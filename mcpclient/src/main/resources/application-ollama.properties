# Ollama Profile Configuration
spring.ai.model.chat=ollama

spring.ai.ollama.base-url=http://localhost:11434
# spring.ai.ollama.chat.options.model=llama3.2:1b
spring.ai.ollama.chat.options.model=llama3.1:8b
spring.ai.ollama.init.pull-model-strategy=when_missing

# Disable OpenAI auto-configurations when using Ollama
spring.autoconfigure.exclude=\
  org.springframework.ai.model.openai.autoconfigure.OpenAiAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiChatAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiEmbeddingAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiImageAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiAudioTranscriptionAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiAudioSpeechAutoConfiguration,\
  org.springframework.ai.model.openai.autoconfigure.OpenAiModerationAutoConfiguration
